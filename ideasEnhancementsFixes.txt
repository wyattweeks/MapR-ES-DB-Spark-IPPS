
to finish project:

- get all queries working in DSR notebook and change demo to work there
- build naritive from carol's blog and post on SE wiki
- move create view script to mapr-job.sh


** add instructions / template for deployment with drill ports open to outside and public dns 
    - copy deploy template from paul's latest and make these changes and save - then ask him to publish as 'healthcare demo'
        - ports for drill
        - include .zip of .sh script

- add images and narrative from carol's blog to demo / readme doc
- learn query syntax for db-shell in #6 readme  
- get this working (add after #3 in the readme)
    # this part - Spark SQL - is an OPTION to the step above
    # in a sparate terminal window, start the spark shell with this command
    # add paramenter to spark version
    # need to automate the 'copy paste step below'
    #$ /opt/mapr/spark/spark-2.2.1/bin/spark-shell --master local[2]
    #copy paste  from the scripts/sparkshell file to query MapR-DB
# WW - FUTURE enhancement - add Drill query on Mapr-ES
# get cluster check script to work in demosetup.sh (currently commented out)

### Git Repo for Project
MapR-ES-DB-Spark-Payments project has been cloned to /public_data/demos_healthcare/MapR-ES-DB-Spark-Payments (source = git clone http://git.se.corp.maprtech.com/wweeks/MapR-ES-DB-Spark-Payments.git)
Manually refresh when repo changes (see steps below)
maven rebuilds jars in /public_data/demos_healthcare/MapR-ES-DB-Spark-Payments/target

 To refresh the project code on /public_data (from se git repo):
        1 - ssh to the edge node of your deployment as user 'mapr'
        2 - $ cd /public_data/demos_healthcare/MapR-ES-DB-Spark-Payments
        3 - $ git pull 
        4 - $ mvn clean install


create multiple topics, so can run 3 consumers / 2 producers --- amend demosetup.sh to create additional topics AND readme script to 
launch 3 versions of producers/consumers, via run-time arguments in carol's original code (optionally)
this change will start with scala code in repo 
this change takes care or the to do note below
#               ### (TO DO NOTE FOR WW - experiment and future demo enhancement: ok to start multiple concurrent producers, interactively.  can start multiple concurrent consumers
#               ###                     interactively, and one will eventualld fail-over to the other/s with error e.g.:
#               ###                           (18/05/04 18:33:11 ERROR scheduler.JobScheduler: Error generating jobs for time 1525458790000 ms
#               ###                           org.apache.kafka.common.errors.UnknownTopicOrPartitionException: No such file or directory (2) Could not seek
#               ###                           2018-05-04 18:33:11,0013 ERROR StreamsListener fs/client/marlin/cc/listener/listenerimpl.cc:803 Thread: 14234 Seek called on unsubscribed partitions
#               ###                           2018-05-04 18:33:11,0013 ERROR StreamsListener fs/client/marlin/cc/listener/jni_listener.cc:756 Thread: 14234 Seek failed with err:2)
#               ###                           Exception in thread "main" org.apache.kafka.common.errors.UnknownTopicOrPartitionException: No such file or directory (2) Could not seek
#               ###                     1 - can i add a consumer group / partition and run these multiple consumer clients in that group, to demonstrate consumer client failover?
#               ###                     2 - also, could replicate stream and bring into demo/talk track)
#


For presentation purposes, you may more than one consumer client manually, from a separate terminal window
        Note: you'll see the client looking for data in the stream, but unless you stop the auto-deployed consumer, it won't actually consume data from the stream,
        as the original consumer client is capable of consuming all the data being produced.  OR the original consumer client may fail (due to a conflict in reading 
        from the stream partition), in which case, this newly launched consumer will pick up where the other left off) See future enhancement on this.


# Git Clone MapR-ES-DB-Spark-Payments project - done @  /public_data/demos_healthcare/MapR-ES-DB-Spark-Payments (git clone http://git.se.corp.maprtech.com/wweeks/MapR-ES-DB-Spark-Payments.git)
# Manually refresh when repo changes @ http://git.se.corp.maprtech.com/wweeks/MapR-ES-DB-Spark-Payments.git 
# maven rebuilds jars in /public_data/demos_healthcare/MapR-ES-DB-Spark-Payments/target
#    `mapr-es-db-spark-payment/target/mapr-es-db-spark-payment-1.0.jar`
#    `mapr-es-db-spark-payment/target/mapr-es-db-spark-payment-1.0-jar-with-dependencies.jar`
# (set auto refresh in future?)
# $ cd /public_data/demos_healthcare/MapR-ES-DB-Spark-Payments
# $ git pull 
# $ mvn clean install

GoogleMaps API for Tableau use 
#API key = AIzaSyCCVEaGnTYrPh394VS9V2X6gSZRSKkOBy0
#URL to embed  https://www.google.com/maps/embed/v1/view?key=AIzaSyCCVEaGnTYrPh394VS9V2X6gSZRSKkOBy0&center=39.5501,105.7821&zoom=8&maptype=roadmap
